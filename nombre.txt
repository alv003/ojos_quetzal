    def estabilizador_imagen(self, imagen_base, imagen_a_estabilizar, radio=0.75, error_reproyeccion=4.0,
                             coincidencias=False):
        """This class returns a sequence of images taken from the camera stabilized with respect to the first image"""

        # Get keypoints and features
        (kpsBase, featuresBase) = self.obtener_puntos_interes(imagen_base)
        (kpsAdicional, featuresAdicional) = self.obtener_puntos_interes(imagen_a_estabilizar)

        # Find matches
        M = self.encontrar_coincidencias(imagen_base, imagen_a_estabilizar, kpsBase, kpsAdicional, featuresBase,
                                         featuresAdicional, radio)

        if M is None:
            print("Not enough matches")
            return None

        if len(M) > 4:
            # Construct the two sets of points
            ptsA = np.float32([kpsBase[i].pt for (_, i) in M])
            ptsB = np.float32([kpsAdicional[i].pt for (i, _) in M])

            # Compute the homography between the two sets of points
            (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, reprojThresh)

            # Apply homography to stabilize the second image
            estabilizada = cv2.warpPerspective(imagen_a_estabilizar, H, (imagen_base.shape[1], imagen_base.shape[0]))
            return estabilizada

        print("No matches found")
        return None

    def img_alignment_sequoia(self, img_base, img_a_estabilizar, width, height):
        """This class takes two images and makes a photogrammetric alignment.
           Returns two aligned images"""

        # Resize images to the same size
        base_resized = cv2.resize(img_base, (width, height), interpolation=cv2.INTER_LINEAR)
        additional_resized = cv2.resize(img_a_estabilizar, (width, height), interpolation=cv2.INTER_LINEAR)

        # Stabilize the second image with respect to the first image
        stabilized_image = self.estabilizador_imagen(base_resized, additional_resized)

        return base_resized, stabilized_image


CODIGO PARA VIDEO 

# Open the video files
cap_RED = cv2.VideoCapture('/path/to/your/video_RED.mp4')
cap_NIR = cv2.VideoCapture('/path/to/your/video_NIR.mp4')

# Check if video opened successfully
if (cap_RED.isOpened()== False or cap_NIR.isOpened()== False): 
  print("Error opening video stream or file")

# Read until video is completed
while(cap_RED.isOpened() and cap_NIR.isOpened()):
  # Capture frame-by-frame
  ret_RED, frame_RED = cap_RED.read()
  ret_NIR, frame_NIR = cap_NIR.read()
  
  if ret_RED == True and ret_NIR == True:
    # img_base_NIR, img_RED, width, height
    stb_NIR, stb_RED =  correccion_img.img_alignment_sequoia(frame_NIR, frame_RED, width, height)
    merged_fix_stb = cv2.merge((stb_RED,stb_RED, stb_NIR))

    # Use matplotlib to show the images
    plt.figure()
    plt.imshow(merged_fix_stb)
    plt.title('Aligned image')
    plt.show()

  # Break the loop
  else: 
    break

# When everything done, release the video capture object
cap_RED.release()
cap_NIR.release()

# Closes all the frames
cv2.destroyAllWindows()